[2024/03/28 09:54-INFO-font_manager.py(1443)] >> generated new fontManager
[2024/03/28 09:54-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 09:55-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 09:57-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 10:48-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 11:16-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 16:16-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 16:37-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 17:01-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 17:04-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 17:38-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 17:44-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 17:46-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 17:49-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 17:49-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 17:54-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 18:26-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 19:15-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 19:31-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 19:43-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:03-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:03-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-d4f78840490dcc05/0.0.0)
[2024/03/28 20:04-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:04-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-d4f78840490dcc05/0.0.0)
[2024/03/28 20:05-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:05-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-d4f78840490dcc05/0.0.0)
[2024/03/28 20:11-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:20-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:23-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:27-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:33-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:33-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 20:34-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:34-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 20:34-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0/cache-1cbe32ffe9c23c0f.arrow
[2024/03/28 20:36-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:36-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 20:36-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:37-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 20:37-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0/cache-1cbe32ffe9c23c0f.arrow
[2024/03/28 20:38-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:38-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 20:39-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0/cache-1cbe32ffe9c23c0f.arrow
[2024/03/28 20:40-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:40-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 20:43-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0/cache-1cbe32ffe9c23c0f.arrow
[2024/03/28 20:43-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:43-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 20:43-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0/cache-1cbe32ffe9c23c0f.arrow
[2024/03/28 20:44-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:44-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 20:45-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0/cache-1cbe32ffe9c23c0f.arrow
[2024/03/28 20:46-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:46-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 20:46-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0/cache-1cbe32ffe9c23c0f.arrow
[2024/03/28 20:47-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:47-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 20:50-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0/cache-1cbe32ffe9c23c0f.arrow
[2024/03/28 20:57-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:57-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 20:57-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0/cache-1cbe32ffe9c23c0f.arrow
[2024/03/28 20:58-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 20:58-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-312471fe715a10e0/0.0.0)
[2024/03/28 20:58-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 20:58-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0/cache-1cbe32ffe9c23c0f.arrow
[2024/03/28 21:22-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 21:22-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-312471fe715a10e0/0.0.0)
[2024/03/28 21:22-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 21:22-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-312471fe715a10e0/0.0.0/cache-961daf615d0d0a47.arrow
[2024/03/28 21:22-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0/cache-1cbe32ffe9c23c0f.arrow
[2024/03/28 21:25-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 21:25-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-312471fe715a10e0/0.0.0)
[2024/03/28 21:25-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0)
[2024/03/28 21:25-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-6457c0d5837dfef2/0.0.0/cache-1cbe32ffe9c23c0f.arrow
[2024/03/28 21:25-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-312471fe715a10e0/0.0.0/cache-961daf615d0d0a47.arrow
[2024/03/28 21:27-WARNING-error.py(97)] >> No route found for IPv6 destination :: (no default route?)
[2024/03/28 21:27-WARNING-builder.py(816)] >> Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-312471fe715a10e0/0.0.0)
[2024/03/28 21:27-WARNING-arrow_dataset.py(3062)] >> Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-312471fe715a10e0/0.0.0/cache-961daf615d0d0a47.arrow
[2024/03/29 18:51-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 18:51-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 18:51-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 18:51-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 18:51-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 18:51-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_18-51-48_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 18:51-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 18:51-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 19:08-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 19:08-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 19:08-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 19:08-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 19:08-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 19:08-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 19:08-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_19-08-00_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 19:08-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 19:08-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 19:08-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 19:19-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 19:19-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 19:19-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 19:19-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 19:19-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 19:19-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 19:19-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_19-19-37_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 19:19-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 19:19-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 19:19-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 19:24-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 19:24-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 19:24-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 19:24-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 19:24-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 19:24-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 19:24-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_19-24-19_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 19:24-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 19:24-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 19:24-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 19:59-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 19:59-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 19:59-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 19:59-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 19:59-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 19:59-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 19:59-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_19-59-49_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 19:59-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 19:59-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 19:59-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 20:13-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 20:13-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 20:13-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 20:13-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 20:13-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_20-13-21_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 20:13-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 20:13-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 20:13-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 20:13-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 20:13-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 20:18-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 20:18-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 20:18-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 20:18-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 20:18-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 20:18-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 20:18-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 20:18-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_20-18-05_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 20:18-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 20:18-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 20:18-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 20:18-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 20:18-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 20:18-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 20:18-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_20-18-42_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 20:18-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 20:18-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 20:18-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 20:18-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 20:18-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 20:30-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 20:30-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 20:30-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 20:30-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 20:30-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 20:30-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 20:30-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_20-30-30_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 20:30-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 20:30-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 20:30-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 20:30-INFO-session_dataset.py(169)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1x613104
[2024/03/29 20:30-INFO-session_dataset.py(73)] >> 文件大小 1 613104
[2024/03/29 20:30-INFO-session_dataset.py(169)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1x613104
[2024/03/29 20:30-INFO-session_dataset.py(73)] >> 文件大小 1 613104
[2024/03/29 22:03-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 22:03-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 22:03-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 22:03-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 22:03-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_22-03-13_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 22:03-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 22:03-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 22:03-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 22:03-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 22:03-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 22:03-INFO-session_dataset.py(169)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 838859x80
[2024/03/29 22:03-INFO-session_dataset.py(73)] >> 文件大小 838859 80
[2024/03/29 22:03-INFO-session_dataset.py(169)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 838859x80
[2024/03/29 22:03-INFO-session_dataset.py(73)] >> 文件大小 838859 80
[2024/03/29 22:08-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 22:08-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 22:08-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 22:08-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 22:08-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 22:08-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 22:08-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 22:08-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_22-08-09_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 22:08-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 22:08-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 22:08-INFO-session_dataset.py(177)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 838859x80
[2024/03/29 22:08-INFO-session_dataset.py(74)] >> 文件大小 838859 80
[2024/03/29 22:08-INFO-session_dataset.py(177)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 838859x80
[2024/03/29 22:08-INFO-session_dataset.py(74)] >> 文件大小 838859 80
[2024/03/29 22:11-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 22:11-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 22:11-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 22:11-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 22:11-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 22:11-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 22:11-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_22-11-21_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 22:11-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 22:11-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 22:11-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 22:11-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 838859x80
[2024/03/29 22:11-INFO-session_dataset.py(74)] >> 文件大小 838859 80
[2024/03/29 22:11-INFO-session_dataset.py(91)] >> labels 3
[2024/03/29 22:11-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 838859x80
[2024/03/29 22:11-INFO-session_dataset.py(74)] >> 文件大小 838859 80
[2024/03/29 22:11-INFO-session_dataset.py(91)] >> labels 3
[2024/03/29 22:12-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 209715x80
[2024/03/29 22:12-INFO-session_dataset.py(74)] >> 文件大小 209715 80
[2024/03/29 22:12-INFO-session_dataset.py(91)] >> labels 1
[2024/03/29 22:12-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 209715x80
[2024/03/29 22:12-INFO-session_dataset.py(74)] >> 文件大小 209715 80
[2024/03/29 22:12-INFO-session_dataset.py(91)] >> labels 1
[2024/03/29 22:29-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/29 22:29-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/29 22:29-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 22:29-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 22:29-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 22:29-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/29 22:29-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/29 22:29-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar29_22-29-01_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/29 22:29-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/29 22:29-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/29 22:29-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 838859x80
[2024/03/29 22:29-INFO-session_dataset.py(74)] >> 文件大小 838859 80
[2024/03/29 22:29-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 838859x80
[2024/03/29 22:29-INFO-session_dataset.py(74)] >> 文件大小 838859 80
[2024/03/29 22:29-INFO-session_dataset.py(91)] >> labels 3
[2024/03/29 22:29-INFO-session_dataset.py(91)] >> labels 3
[2024/03/29 22:29-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 209715x80
[2024/03/29 22:29-INFO-session_dataset.py(74)] >> 文件大小 209715 80
[2024/03/29 22:29-INFO-session_dataset.py(91)] >> labels 1
[2024/03/29 22:29-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 209715x80
[2024/03/29 22:29-INFO-session_dataset.py(74)] >> 文件大小 209715 80
[2024/03/29 22:29-INFO-session_dataset.py(91)] >> labels 1
[2024/03/30 17:00-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/30 17:00-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/30 17:00-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 17:00-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 17:00-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar30_17-00-36_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/30 17:00-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 17:00-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/30 17:00-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 18:43-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/30 18:43-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/30 18:43-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 18:43-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 18:43-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 18:43-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 18:43-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar30_18-43-07_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/30 18:43-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 18:43-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 18:43-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/30 18:43-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 838859x80
[2024/03/30 18:43-INFO-session_dataset.py(74)] >> 文件大小 838859 80
[2024/03/30 18:43-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 838859x80
[2024/03/30 18:43-INFO-session_dataset.py(74)] >> 文件大小 838859 80
[2024/03/30 18:43-INFO-session_dataset.py(91)] >> labels 3
[2024/03/30 18:43-INFO-session_dataset.py(91)] >> labels 3
[2024/03/30 18:43-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 209715x80
[2024/03/30 18:43-INFO-session_dataset.py(74)] >> 文件大小 209715 80
[2024/03/30 18:43-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 209715x80
[2024/03/30 18:43-INFO-session_dataset.py(74)] >> 文件大小 209715 80
[2024/03/30 18:43-INFO-session_dataset.py(91)] >> labels 1
[2024/03/30 18:43-INFO-session_dataset.py(91)] >> labels 1
[2024/03/30 20:38-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/30 20:38-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/30 20:38-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 20:38-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 20:38-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar30_20-38-52_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/30 20:38-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 20:38-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/30 20:38-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 20:38-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 20:38-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 20:38-INFO-font_manager.py(1544)] >> generated new fontManager
[2024/03/30 20:38-INFO-font_manager.py(1544)] >> generated new fontManager
[2024/03/30 20:41-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/30 20:41-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/30 20:41-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 20:41-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 20:41-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar30_20-41-46_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/30 20:41-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 20:41-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/30 20:41-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 20:41-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 20:41-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 20:42-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 589592x3
[2024/03/30 20:42-INFO-session_dataset.py(74)] >> 文件大小 589592 3
[2024/03/30 20:42-INFO-session_dataset.py(91)] >> labels 6
[2024/03/30 20:42-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 589592x3
[2024/03/30 20:42-INFO-session_dataset.py(74)] >> 文件大小 589592 3
[2024/03/30 20:42-INFO-session_dataset.py(91)] >> labels 6
[2024/03/30 20:42-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 147398x3
[2024/03/30 20:42-INFO-session_dataset.py(74)] >> 文件大小 147398 3
[2024/03/30 20:42-INFO-session_dataset.py(91)] >> labels 2
[2024/03/30 20:42-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 147398x3
[2024/03/30 20:42-INFO-session_dataset.py(74)] >> 文件大小 147398 3
[2024/03/30 20:42-INFO-session_dataset.py(91)] >> labels 2
[2024/03/30 20:44-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/30 20:44-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/30 20:44-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 20:44-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 20:44-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar30_20-44-23_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/30 20:44-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 20:44-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/30 20:44-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 20:44-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 20:44-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 20:48-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/30 20:48-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/30 20:48-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 20:48-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 20:48-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 20:48-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 20:48-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar30_20-48-45_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/30 20:48-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 20:48-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 20:48-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/30 20:49-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 162543x3
[2024/03/30 20:49-INFO-session_dataset.py(74)] >> 文件大小 162543 3
[2024/03/30 20:49-INFO-session_dataset.py(91)] >> labels 5
[2024/03/30 20:49-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 162543x3
[2024/03/30 20:49-INFO-session_dataset.py(74)] >> 文件大小 162543 3
[2024/03/30 20:49-INFO-session_dataset.py(91)] >> labels 5
[2024/03/30 20:49-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 40636x3
[2024/03/30 20:49-INFO-session_dataset.py(74)] >> 文件大小 40636 3
[2024/03/30 20:49-INFO-session_dataset.py(91)] >> labels 1
[2024/03/30 20:49-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 40636x3
[2024/03/30 20:49-INFO-session_dataset.py(74)] >> 文件大小 40636 3
[2024/03/30 20:49-INFO-session_dataset.py(91)] >> labels 1
[2024/03/30 21:06-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/30 21:06-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/30 21:06-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 21:06-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 21:06-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 21:06-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 21:06-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 21:06-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar30_21-06-06_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/30 21:06-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 21:06-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/30 21:06-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 162543x3
[2024/03/30 21:06-INFO-session_dataset.py(74)] >> 文件大小 162543 3
[2024/03/30 21:06-INFO-session_dataset.py(91)] >> labels 5
[2024/03/30 21:06-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 40636x3
[2024/03/30 21:06-INFO-session_dataset.py(74)] >> 文件大小 40636 3
[2024/03/30 21:06-INFO-session_dataset.py(91)] >> labels 1
[2024/03/30 21:06-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 162543x3
[2024/03/30 21:06-INFO-session_dataset.py(74)] >> 文件大小 162543 3
[2024/03/30 21:06-INFO-session_dataset.py(91)] >> labels 5
[2024/03/30 21:06-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 40636x3
[2024/03/30 21:06-INFO-session_dataset.py(74)] >> 文件大小 40636 3
[2024/03/30 21:06-INFO-session_dataset.py(91)] >> labels 1
[2024/03/30 21:10-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/30 21:10-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/30 21:10-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 21:10-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 21:10-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 21:10-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 21:10-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 21:10-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar30_21-10-05_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/30 21:10-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 21:10-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/30 21:10-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 162543x3
[2024/03/30 21:10-INFO-session_dataset.py(74)] >> 文件大小 162543 3
[2024/03/30 21:10-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 162543x3
[2024/03/30 21:10-INFO-session_dataset.py(74)] >> 文件大小 162543 3
[2024/03/30 21:10-INFO-session_dataset.py(91)] >> labels 5
[2024/03/30 21:10-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 40636x3
[2024/03/30 21:10-INFO-session_dataset.py(74)] >> 文件大小 40636 3
[2024/03/30 21:10-INFO-session_dataset.py(91)] >> labels 1
[2024/03/30 21:10-INFO-session_dataset.py(91)] >> labels 5
[2024/03/30 21:10-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 40636x3
[2024/03/30 21:10-INFO-session_dataset.py(74)] >> 文件大小 40636 3
[2024/03/30 21:10-INFO-session_dataset.py(91)] >> labels 1
[2024/03/30 21:22-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/30 21:22-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/30 21:22-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 21:22-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/30 21:22-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 21:22-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/30 21:22-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar30_21-22-48_autodl-container-a9b6118852-8db46574,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/30 21:22-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 21:22-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/30 21:22-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/30 21:22-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 203040x3
[2024/03/30 21:22-INFO-session_dataset.py(74)] >> 文件大小 203040 3
[2024/03/30 21:22-INFO-session_dataset.py(91)] >> labels 6
[2024/03/30 21:22-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 203040x3
[2024/03/30 21:22-INFO-session_dataset.py(74)] >> 文件大小 203040 3
[2024/03/30 21:22-INFO-session_dataset.py(91)] >> labels 6
[2024/03/30 21:22-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 50760x3
[2024/03/30 21:22-INFO-session_dataset.py(74)] >> 文件大小 50760 3
[2024/03/30 21:22-INFO-session_dataset.py(91)] >> labels 1
[2024/03/30 21:22-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 50760x3
[2024/03/30 21:22-INFO-session_dataset.py(74)] >> 文件大小 50760 3
[2024/03/30 21:22-INFO-session_dataset.py(91)] >> labels 1
[2024/03/31 15:23-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/31 15:23-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/31 15:23-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/31 15:23-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/31 15:23-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/31 15:23-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/31 15:23-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/31 15:23-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar31_15-23-42_autodl-container-81b6119c52-f3eff239,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/31 15:23-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/31 15:23-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/31 15:23-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 203040x3
[2024/03/31 15:23-INFO-session_dataset.py(74)] >> 文件大小 203040 3
[2024/03/31 15:23-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 203040x3
[2024/03/31 15:23-INFO-session_dataset.py(74)] >> 文件大小 203040 3
[2024/03/31 15:23-INFO-session_dataset.py(91)] >> labels 6
[2024/03/31 15:23-INFO-session_dataset.py(91)] >> labels 6
[2024/03/31 15:23-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 50760x3
[2024/03/31 15:23-INFO-session_dataset.py(74)] >> 文件大小 50760 3
[2024/03/31 15:23-INFO-session_dataset.py(91)] >> labels 1
[2024/03/31 15:23-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 50760x3
[2024/03/31 15:23-INFO-session_dataset.py(74)] >> 文件大小 50760 3
[2024/03/31 15:23-INFO-session_dataset.py(91)] >> labels 1
[2024/03/31 19:12-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/31 19:12-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/31 19:12-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/31 19:12-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/31 19:12-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/31 19:12-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/31 19:12-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar31_19-12-47_autodl-container-bdbc119a52-77ec9aaf,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/31 19:12-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/31 19:12-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/31 19:12-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/31 19:12-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 203040x3
[2024/03/31 19:12-INFO-session_dataset.py(74)] >> 文件大小 203040 3
[2024/03/31 19:12-INFO-session_dataset.py(91)] >> labels 6
[2024/03/31 19:12-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 203040x3
[2024/03/31 19:12-INFO-session_dataset.py(74)] >> 文件大小 203040 3
[2024/03/31 19:12-INFO-session_dataset.py(91)] >> labels 6
[2024/03/31 19:12-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 50760x3
[2024/03/31 19:12-INFO-session_dataset.py(74)] >> 文件大小 50760 3
[2024/03/31 19:12-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 50760x3
[2024/03/31 19:12-INFO-session_dataset.py(74)] >> 文件大小 50760 3
[2024/03/31 19:12-INFO-session_dataset.py(91)] >> labels 1
[2024/03/31 19:12-INFO-session_dataset.py(91)] >> labels 1
[2024/03/31 19:34-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/03/31 19:34-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/03/31 19:34-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/31 19:34-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/03/31 19:34-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/31 19:34-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/31 19:34-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/03/31 19:34-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Mar31_19-34-01_autodl-container-bdbc119a52-77ec9aaf,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/03/31 19:34-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/03/31 19:34-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/03/31 19:34-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 203040x3
[2024/03/31 19:34-INFO-session_dataset.py(74)] >> 文件大小 203040 3
[2024/03/31 19:34-INFO-session_dataset.py(91)] >> labels 6
[2024/03/31 19:34-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 50760x3
[2024/03/31 19:34-INFO-session_dataset.py(74)] >> 文件大小 50760 3
[2024/03/31 19:34-INFO-session_dataset.py(91)] >> labels 1
[2024/03/31 19:34-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 203040x3
[2024/03/31 19:34-INFO-session_dataset.py(74)] >> 文件大小 203040 3
[2024/03/31 19:34-INFO-session_dataset.py(91)] >> labels 6
[2024/03/31 19:34-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 50760x3
[2024/03/31 19:34-INFO-session_dataset.py(74)] >> 文件大小 50760 3
[2024/03/31 19:34-INFO-session_dataset.py(91)] >> labels 1
[2024/04/01 14:53-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/01 14:53-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/01 14:53-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/01 14:53-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/01 14:53-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/01 14:53-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr01_14-53-12_autodl-container-bdbc119a52-77ec9aaf,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/01 14:53-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/01 14:53-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/01 16:55-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/01 16:55-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/01 16:55-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/01 16:55-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/01 16:55-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/01 16:55-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/01 16:55-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr01_16-55-14_autodl-container-bdbc119a52-77ec9aaf,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/01 16:55-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/01 16:55-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/01 16:55-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/01 17:33-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/01 17:33-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/01 17:33-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/01 17:33-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/01 17:33-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/01 17:33-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/01 17:33-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr01_17-33-41_autodl-container-bdbc119a52-77ec9aaf,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/01 17:33-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/01 17:33-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/01 17:33-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/01 17:33-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 58837x3
[2024/04/01 17:33-INFO-session_dataset.py(74)] >> 文件大小 58837 3
[2024/04/01 17:33-INFO-session_dataset.py(91)] >> labels 2
[2024/04/01 17:33-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 58837x3
[2024/04/01 17:33-INFO-session_dataset.py(74)] >> 文件大小 58837 3
[2024/04/01 17:33-INFO-session_dataset.py(91)] >> labels 2
[2024/04/01 17:33-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 14710x3
[2024/04/01 17:33-INFO-session_dataset.py(74)] >> 文件大小 14710 3
[2024/04/01 17:33-INFO-session_dataset.py(91)] >> labels 2
[2024/04/01 17:33-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 14710x3
[2024/04/01 17:33-INFO-session_dataset.py(74)] >> 文件大小 14710 3
[2024/04/01 17:33-INFO-session_dataset.py(91)] >> labels 2
[2024/04/04 21:53-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/04 21:53-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/04 21:53-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/04 21:53-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/04 21:53-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/04 21:53-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/04 21:53-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr04_21-53-01_autodl-container-81b6119c52-f3eff239,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/04 21:53-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/04 21:53-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/04 21:53-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/04 21:53-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 58837x3
[2024/04/04 21:53-INFO-session_dataset.py(74)] >> 文件大小 58837 3
[2024/04/04 21:53-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 58837x3
[2024/04/04 21:53-INFO-session_dataset.py(74)] >> 文件大小 58837 3
[2024/04/04 21:53-INFO-session_dataset.py(91)] >> labels 2
[2024/04/04 21:53-INFO-session_dataset.py(91)] >> labels 2
[2024/04/04 21:53-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 14710x3
[2024/04/04 21:53-INFO-session_dataset.py(74)] >> 文件大小 14710 3
[2024/04/04 21:53-INFO-session_dataset.py(91)] >> labels 2
[2024/04/04 21:53-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 14710x3
[2024/04/04 21:53-INFO-session_dataset.py(74)] >> 文件大小 14710 3
[2024/04/04 21:53-INFO-session_dataset.py(91)] >> labels 2
[2024/04/09 14:46-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/09 14:46-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/09 14:46-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/09 14:46-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/09 14:46-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/09 14:46-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/09 14:46-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr09_14-46-06_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/09 14:46-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/09 14:46-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/09 14:46-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/09 14:46-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1219752x3
[2024/04/09 14:46-INFO-session_dataset.py(74)] >> 文件大小 1219752 3
[2024/04/09 14:46-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 14:46-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1219752x3
[2024/04/09 14:46-INFO-session_dataset.py(74)] >> 文件大小 1219752 3
[2024/04/09 14:46-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 14:49-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/09 14:49-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/09 14:49-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/09 14:49-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/09 14:49-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr09_14-49-56_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/09 14:49-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/09 14:49-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/09 14:49-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/09 14:49-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/09 14:49-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/09 14:50-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1219752x3
[2024/04/09 14:50-INFO-session_dataset.py(74)] >> 文件大小 1219752 3
[2024/04/09 14:50-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1219752x3
[2024/04/09 14:50-INFO-session_dataset.py(74)] >> 文件大小 1219752 3
[2024/04/09 14:50-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 14:50-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 14:50-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 4879004x3
[2024/04/09 14:50-INFO-session_dataset.py(74)] >> 文件大小 4879004 3
[2024/04/09 14:50-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 14:50-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 4879004x3
[2024/04/09 14:50-INFO-session_dataset.py(74)] >> 文件大小 4879004 3
[2024/04/09 14:50-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 14:50-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/09 14:50-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/09 14:50-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/09 14:50-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/09 14:50-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/09 14:50-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/09 14:50-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr09_14-50-36_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/09 14:50-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/09 14:50-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/09 14:50-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/09 14:50-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1219752x3
[2024/04/09 14:50-INFO-session_dataset.py(74)] >> 文件大小 1219752 3
[2024/04/09 14:50-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1219752x3
[2024/04/09 14:50-INFO-session_dataset.py(74)] >> 文件大小 1219752 3
[2024/04/09 14:50-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 14:50-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 14:50-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 4879004x3
[2024/04/09 14:50-INFO-session_dataset.py(74)] >> 文件大小 4879004 3
[2024/04/09 14:50-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 4879004x3
[2024/04/09 14:50-INFO-session_dataset.py(74)] >> 文件大小 4879004 3
[2024/04/09 14:50-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 14:50-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 15:00-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/09 15:00-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/09 15:00-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/09 15:00-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/09 15:00-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr09_15-00-48_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/09 15:00-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/09 15:00-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/09 15:00-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/09 15:00-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/09 15:00-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/09 15:00-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1219752x3
[2024/04/09 15:00-INFO-session_dataset.py(74)] >> 文件大小 1219752 3
[2024/04/09 15:00-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 15:00-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1219752x3
[2024/04/09 15:00-INFO-session_dataset.py(74)] >> 文件大小 1219752 3
[2024/04/09 15:00-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 15:01-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 4879004x3
[2024/04/09 15:01-INFO-session_dataset.py(74)] >> 文件大小 4879004 3
[2024/04/09 15:01-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 4879004x3
[2024/04/09 15:01-INFO-session_dataset.py(74)] >> 文件大小 4879004 3
[2024/04/09 15:01-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 15:01-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 15:01-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/09 15:01-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/09 15:01-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/09 15:01-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/09 15:01-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/09 15:01-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/09 15:01-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/09 15:01-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr09_15-01-39_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/09 15:01-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/09 15:01-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/09 15:01-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1219752x3
[2024/04/09 15:01-INFO-session_dataset.py(74)] >> 文件大小 1219752 3
[2024/04/09 15:01-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1219752x3
[2024/04/09 15:01-INFO-session_dataset.py(74)] >> 文件大小 1219752 3
[2024/04/09 15:01-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 15:01-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 15:02-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 4879004x3
[2024/04/09 15:02-INFO-session_dataset.py(74)] >> 文件大小 4879004 3
[2024/04/09 15:02-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 4879004x3
[2024/04/09 15:02-INFO-session_dataset.py(74)] >> 文件大小 4879004 3
[2024/04/09 15:02-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 15:02-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 15:08-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/09 15:08-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/09 15:08-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/09 15:08-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/09 15:08-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/09 15:08-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/09 15:08-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/09 15:08-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr09_15-08-40_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/09 15:08-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/09 15:08-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/09 15:08-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1219752x3
[2024/04/09 15:08-INFO-session_dataset.py(74)] >> 文件大小 1219752 3
[2024/04/09 15:08-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75train.pkl, size 1219752x3
[2024/04/09 15:08-INFO-session_dataset.py(74)] >> 文件大小 1219752 3
[2024/04/09 15:08-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 15:08-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 15:09-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 4879004x3
[2024/04/09 15:09-INFO-session_dataset.py(74)] >> 文件大小 4879004 3
[2024/04/09 15:09-INFO-session_dataset.py(91)] >> labels 7
[2024/04/09 15:09-INFO-session_dataset.py(180)] >> read ./data/IDS2018_4096/pretrain4096_0.75test.pkl, size 4879004x3
[2024/04/09 15:09-INFO-session_dataset.py(74)] >> 文件大小 4879004 3
[2024/04/09 15:09-INFO-session_dataset.py(91)] >> labels 7
[2024/04/10 10:32-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/10 10:32-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/10 10:32-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/10 10:32-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/10 10:32-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr10_10-32-55_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/10 10:32-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/10 10:32-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/10 10:32-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/10 10:32-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/10 10:32-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/10 10:32-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 3000x3
[2024/04/10 10:32-INFO-session_dataset.py(74)] >> 文件大小 3000 3
[2024/04/10 10:32-INFO-session_dataset.py(91)] >> labels 4
[2024/04/10 10:32-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 3000x3
[2024/04/10 10:32-INFO-session_dataset.py(74)] >> 文件大小 3000 3
[2024/04/10 10:32-INFO-session_dataset.py(91)] >> labels 4
[2024/04/10 10:32-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 27000x3
[2024/04/10 10:32-INFO-session_dataset.py(74)] >> 文件大小 27000 3
[2024/04/10 10:32-INFO-session_dataset.py(91)] >> labels 4
[2024/04/10 10:32-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 27000x3
[2024/04/10 10:32-INFO-session_dataset.py(74)] >> 文件大小 27000 3
[2024/04/10 10:32-INFO-session_dataset.py(91)] >> labels 4
[2024/04/11 15:41-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/11 15:41-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/11 15:41-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/11 15:41-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/11 15:41-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr11_15-41-09_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/11 15:41-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/11 15:41-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/11 15:41-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/11 15:41-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/11 15:41-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/11 15:41-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2480x3
[2024/04/11 15:41-INFO-session_dataset.py(74)] >> 文件大小 2480 3
[2024/04/11 15:41-INFO-session_dataset.py(91)] >> labels 6
[2024/04/11 15:41-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2480x3
[2024/04/11 15:41-INFO-session_dataset.py(74)] >> 文件大小 2480 3
[2024/04/11 15:41-INFO-session_dataset.py(91)] >> labels 6
[2024/04/11 15:41-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 22330x3
[2024/04/11 15:41-INFO-session_dataset.py(74)] >> 文件大小 22330 3
[2024/04/11 15:41-INFO-session_dataset.py(91)] >> labels 6
[2024/04/11 15:41-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 22330x3
[2024/04/11 15:41-INFO-session_dataset.py(74)] >> 文件大小 22330 3
[2024/04/11 15:41-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 00:53-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 00:53-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 00:53-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 00:53-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 00:53-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_00-53-04_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 00:53-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 00:53-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 00:53-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 00:53-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 00:53-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 00:53-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x1
[2024/04/12 00:53-INFO-session_dataset.py(74)] >> 文件大小 2324339 1
[2024/04/12 00:53-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x1
[2024/04/12 00:53-INFO-session_dataset.py(74)] >> 文件大小 2324339 1
[2024/04/12 10:02-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:02-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:02-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:02-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:02-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:02-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:02-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-02-43_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 10:02-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:02-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:02-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:03-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:03-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:03-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:03-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:03-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:03-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:03-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:03-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:03-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:03-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:03-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:03-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:11-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:11-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:11-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:11-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:11-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:11-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:11-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:11-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-11-52_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 10:11-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:11-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:12-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:12-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:12-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:12-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:12-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:12-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:12-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:12-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:12-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:12-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:12-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:12-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:12-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:12-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:12-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:12-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:12-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:12-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:12-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:12-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-12-41_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 10:12-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:12-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:12-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:12-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:12-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:12-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:12-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:12-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:12-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:12-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:12-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:12-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:12-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:12-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:31-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:31-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:31-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:31-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:31-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:31-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:31-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:31-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.1,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-31-08_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=10000,
per_device_train_batch_size=10000,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.2,
xpu_backend=None,
)
[2024/04/12 10:31-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:31-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:31-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:31-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:31-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:31-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:31-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:31-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:31-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:31-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:31-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:31-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:31-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:31-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:32-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:32-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:32-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:32-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:32-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:32-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:32-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:32-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.1,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-32-02_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=5000,
per_device_train_batch_size=5000,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.2,
xpu_backend=None,
)
[2024/04/12 10:32-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:32-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:32-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:32-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:32-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:32-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:32-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:32-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:32-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:32-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:32-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:32-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:32-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:32-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:34-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:34-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:34-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:34-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:34-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:34-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.1,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-34-07_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1000,
per_device_train_batch_size=1000,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.2,
xpu_backend=None,
)
[2024/04/12 10:34-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:34-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:34-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:34-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:34-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:34-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:34-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:34-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:34-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:34-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:34-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:34-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:34-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:34-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:34-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:34-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:36-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:36-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:36-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:36-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:36-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-36-26_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1000,
per_device_train_batch_size=1000,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.2,
xpu_backend=None,
)
[2024/04/12 10:36-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:36-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:36-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:36-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:36-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:36-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:36-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:36-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:36-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:36-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:36-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:36-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:36-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:36-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:36-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:36-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:36-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:38-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:38-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:38-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:38-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:38-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-38-38_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1000,
per_device_train_batch_size=1000,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.2,
xpu_backend=None,
)
[2024/04/12 10:38-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:38-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:38-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:38-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:38-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:38-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:38-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:38-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:38-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:38-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:38-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:38-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:38-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:38-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:38-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:38-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:38-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:44-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:44-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:44-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:44-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:44-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:44-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:44-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:44-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-44-18_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=2000,
per_device_train_batch_size=2000,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.2,
xpu_backend=None,
)
[2024/04/12 10:44-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:44-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:44-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:44-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:44-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:44-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:44-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:44-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:44-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:44-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:44-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:44-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:44-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:44-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:46-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:46-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:46-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:46-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:46-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:46-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:46-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-46-50_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=3000,
per_device_train_batch_size=3000,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 10:46-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:46-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:46-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:47-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:47-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:47-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:47-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:47-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:47-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:47-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:47-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:47-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:47-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:47-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:47-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:47-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:47-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:47-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:47-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:47-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-47-30_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=2300,
per_device_train_batch_size=2300,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 10:47-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:47-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:47-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:47-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:47-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:47-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:47-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:47-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:48-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:48-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:48-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:48-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:48-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:48-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:48-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-48-09_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1500,
per_device_train_batch_size=1500,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 10:48-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:48-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:48-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:48-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:48-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:48-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:48-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:48-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:48-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:48-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:48-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:48-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:48-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:48-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:48-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:54-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 10:54-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 10:54-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:54-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 10:54-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:54-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 10:54-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_10-54-11_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1500,
per_device_train_batch_size=1500,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 10:54-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:54-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 10:54-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 10:54-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:54-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:54-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:54-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 10:54-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 10:54-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:54-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:54-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:54-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 10:54-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 10:54-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 10:54-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 14:30-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 14:30-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 14:30-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 14:30-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 14:30-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_14-30-58_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1024,
per_device_train_batch_size=1024,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 14:30-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 14:30-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 14:30-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 14:30-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 14:30-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 14:31-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 14:31-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 14:31-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 14:31-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 14:31-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 14:31-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 14:31-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_14-31-29_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1024,
per_device_train_batch_size=1024,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 14:31-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 14:31-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 14:31-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 14:31-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 14:31-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 14:31-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 14:31-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 2324339x3
[2024/04/12 14:31-INFO-session_dataset.py(74)] >> 文件大小 2324339 3
[2024/04/12 14:31-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 14:31-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 14:31-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 14:31-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 14:31-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 258258x3
[2024/04/12 14:31-INFO-session_dataset.py(74)] >> 文件大小 258258 3
[2024/04/12 14:31-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 16:00-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 16:00-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 16:00-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 16:00-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 16:00-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_16-00-55_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=256,
per_device_train_batch_size=256,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 16:00-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 16:00-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 16:00-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 16:00-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 16:00-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 16:01-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 464867x3
[2024/04/12 16:01-INFO-session_dataset.py(74)] >> 文件大小 464867 3
[2024/04/12 16:01-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 16:01-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 464867x3
[2024/04/12 16:01-INFO-session_dataset.py(74)] >> 文件大小 464867 3
[2024/04/12 16:01-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 16:01-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 51651x3
[2024/04/12 16:01-INFO-session_dataset.py(74)] >> 文件大小 51651 3
[2024/04/12 16:01-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 16:01-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 51651x3
[2024/04/12 16:01-INFO-session_dataset.py(74)] >> 文件大小 51651 3
[2024/04/12 16:01-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 20:20-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 20:20-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 20:20-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 20:20-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 20:20-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 20:20-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 20:20-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 20:20-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_20-20-50_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 20:20-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 20:20-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 20:20-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 46486x3
[2024/04/12 20:20-INFO-session_dataset.py(74)] >> 文件大小 46486 3
[2024/04/12 20:20-INFO-session_dataset.py(91)] >> labels 5
[2024/04/12 20:20-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 46486x3
[2024/04/12 20:20-INFO-session_dataset.py(74)] >> 文件大小 46486 3
[2024/04/12 20:20-INFO-session_dataset.py(91)] >> labels 5
[2024/04/12 20:20-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 5165x3
[2024/04/12 20:20-INFO-session_dataset.py(74)] >> 文件大小 5165 3
[2024/04/12 20:20-INFO-session_dataset.py(91)] >> labels 5
[2024/04/12 20:20-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 5165x3
[2024/04/12 20:20-INFO-session_dataset.py(74)] >> 文件大小 5165 3
[2024/04/12 20:20-INFO-session_dataset.py(91)] >> labels 5
[2024/04/12 20:24-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 20:24-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 20:24-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 20:24-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 20:24-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_20-24-23_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=512,
per_device_train_batch_size=512,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 20:24-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 20:24-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 20:24-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 20:24-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 20:24-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 20:24-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 46486x3
[2024/04/12 20:24-INFO-session_dataset.py(74)] >> 文件大小 46486 3
[2024/04/12 20:24-INFO-session_dataset.py(91)] >> labels 5
[2024/04/12 20:24-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 5165x3
[2024/04/12 20:24-INFO-session_dataset.py(74)] >> 文件大小 5165 3
[2024/04/12 20:24-INFO-session_dataset.py(91)] >> labels 5
[2024/04/12 20:24-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 46486x3
[2024/04/12 20:24-INFO-session_dataset.py(74)] >> 文件大小 46486 3
[2024/04/12 20:24-INFO-session_dataset.py(91)] >> labels 5
[2024/04/12 20:24-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 5165x3
[2024/04/12 20:24-INFO-session_dataset.py(74)] >> 文件大小 5165 3
[2024/04/12 20:24-INFO-session_dataset.py(91)] >> labels 5
[2024/04/12 22:27-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/12 22:27-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/12 22:27-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 22:27-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 22:27-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 22:27-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/12 22:27-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/12 22:27-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4096/runs/Apr12_22-27-38_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4096,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=512,
per_device_train_batch_size=512,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4096,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/12 22:27-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/12 22:27-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/12 22:27-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 94420x3
[2024/04/12 22:27-INFO-session_dataset.py(74)] >> 文件大小 94420 3
[2024/04/12 22:27-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 22:27-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 94420x3
[2024/04/12 22:27-INFO-session_dataset.py(74)] >> 文件大小 94420 3
[2024/04/12 22:27-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 22:27-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 10490x3
[2024/04/12 22:27-INFO-session_dataset.py(74)] >> 文件大小 10490 3
[2024/04/12 22:27-INFO-session_dataset.py(91)] >> labels 6
[2024/04/12 22:27-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 10490x3
[2024/04/12 22:27-INFO-session_dataset.py(74)] >> 文件大小 10490 3
[2024/04/12 22:27-INFO-session_dataset.py(91)] >> labels 6
[2024/04/13 11:53-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/13 11:53-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/13 11:53-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/13 11:53-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/13 11:53-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/13 11:53-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4097/runs/Apr13_11-53-31_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4097,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=512,
per_device_train_batch_size=512,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4097,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.05,
xpu_backend=None,
)
[2024/04/13 11:53-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/13 11:53-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/13 11:53-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/13 11:53-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/13 11:53-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 368840x3
[2024/04/13 11:53-INFO-session_dataset.py(74)] >> 文件大小 368840 3
[2024/04/13 11:53-INFO-session_dataset.py(91)] >> labels 6
[2024/04/13 11:53-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 368840x3
[2024/04/13 11:53-INFO-session_dataset.py(74)] >> 文件大小 368840 3
[2024/04/13 11:53-INFO-session_dataset.py(91)] >> labels 6
[2024/04/13 11:53-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 40981x3
[2024/04/13 11:53-INFO-session_dataset.py(74)] >> 文件大小 40981 3
[2024/04/13 11:53-INFO-session_dataset.py(91)] >> labels 6
[2024/04/13 11:53-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 40981x3
[2024/04/13 11:53-INFO-session_dataset.py(74)] >> 文件大小 40981 3
[2024/04/13 11:53-INFO-session_dataset.py(91)] >> labels 6
[2024/04/13 13:34-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/13 13:34-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/13 13:34-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/13 13:34-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/13 13:34-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/13 13:34-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4097/runs/Apr13_13-34-43_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4097,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=256,
per_device_train_batch_size=256,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4097,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.1,
xpu_backend=None,
)
[2024/04/13 13:34-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/13 13:34-INFO-pretrain.py(122)] >> Training new model from scratch
[2024/04/13 13:34-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/13 13:34-WARNING-pretrain.py(92)] >> You are instantiating a new config instance from scratch.
[2024/04/13 13:34-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 368840x3
[2024/04/13 13:34-INFO-session_dataset.py(74)] >> 文件大小 368840 3
[2024/04/13 13:34-INFO-session_dataset.py(91)] >> labels 6
[2024/04/13 13:34-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75train.pkl, size 368840x3
[2024/04/13 13:34-INFO-session_dataset.py(74)] >> 文件大小 368840 3
[2024/04/13 13:34-INFO-session_dataset.py(91)] >> labels 6
[2024/04/13 13:34-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 40981x3
[2024/04/13 13:34-INFO-session_dataset.py(74)] >> 文件大小 40981 3
[2024/04/13 13:34-INFO-session_dataset.py(91)] >> labels 6
[2024/04/13 13:34-INFO-session_dataset.py(180)] >> read ./data/IDSTestBeforeTrain/pretrain4096_0.75test.pkl, size 40981x3
[2024/04/13 13:34-INFO-session_dataset.py(74)] >> 文件大小 40981 3
[2024/04/13 13:34-INFO-session_dataset.py(91)] >> labels 6
[2024/04/14 23:32-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/14 23:32-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/14 23:32-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/14 23:32-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/14 23:32-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/14 23:32-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/14 23:32-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune-probes/runs/Apr14_23-32-47_autodl-container-d823118352-396a1cdd,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune-probes,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune-probes,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/04/14 23:32-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75train.pkl, size 158621x3
[2024/04/14 23:32-INFO-session_dataset.py(74)] >> 文件大小 158621 3
[2024/04/14 23:32-INFO-session_dataset.py(91)] >> labels 3
[2024/04/14 23:32-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75train.pkl, size 158621x3
[2024/04/14 23:32-INFO-session_dataset.py(74)] >> 文件大小 158621 3
[2024/04/14 23:32-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75test.pkl, size 17624x3
[2024/04/14 23:32-INFO-session_dataset.py(74)] >> 文件大小 17624 3
[2024/04/14 23:32-INFO-session_dataset.py(91)] >> labels 3
[2024/04/14 23:32-INFO-session_dataset.py(91)] >> labels 3
[2024/04/14 23:32-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75test.pkl, size 17624x3
[2024/04/14 23:32-INFO-session_dataset.py(74)] >> 文件大小 17624 3
[2024/04/14 23:32-INFO-session_dataset.py(91)] >> labels 3
[2024/04/15 14:15-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75train.pkl, size 158621x3
[2024/04/15 14:15-INFO-session_dataset.py(74)] >> 文件大小 158621 3
[2024/04/15 14:15-INFO-session_dataset.py(91)] >> labels 3
[2024/04/15 14:15-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75test.pkl, size 17624x3
[2024/04/15 14:15-INFO-session_dataset.py(74)] >> 文件大小 17624 3
[2024/04/15 14:15-INFO-session_dataset.py(91)] >> labels 3
[2024/04/15 14:18-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75test.pkl, size 17624x3
[2024/04/15 14:18-INFO-session_dataset.py(74)] >> 文件大小 17624 3
[2024/04/15 14:18-INFO-session_dataset.py(91)] >> labels 3
[2024/04/15 14:27-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/vit_test_eval/checkpoint-24790/pretrain4096_0.75test.pkl, size 17624x3
[2024/04/15 14:27-INFO-session_dataset.py(74)] >> 文件大小 17624 3
[2024/04/15 14:27-INFO-session_dataset.py(91)] >> labels 3
[2024/04/15 14:27-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/vit_test_eval/checkpoint-19832/pretrain4096_0.75test.pkl, size 17624x3
[2024/04/15 14:27-INFO-session_dataset.py(74)] >> 文件大小 17624 3
[2024/04/15 14:27-INFO-session_dataset.py(91)] >> labels 3
[2024/04/15 14:29-WARNING-font_manager.py(1350)] >> findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.
[2024/04/15 14:29-WARNING-font_manager.py(1355)] >> findfont: Generic family 'serif' not found because none of the following families were found: Times New Roman
[2024/04/15 14:29-WARNING-font_manager.py(1350)] >> findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.
[2024/04/15 14:29-WARNING-font_manager.py(1355)] >> findfont: Generic family 'serif' not found because none of the following families were found: Times New Roman
[2024/04/22 03:15-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/22 03:15-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/22 03:15-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/22 03:15-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/22 03:15-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/22 03:15-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/22 03:15-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune-probes_traceroutes/runs/Apr22_03-15-14_autodl-container-bf3b118d52-f39e3c0e,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune-probes_traceroutes,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune-probes_traceroutes,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/04/22 03:15-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75train.pkl, size 180878x3
[2024/04/22 03:15-INFO-session_dataset.py(74)] >> 文件大小 180878 3
[2024/04/22 03:15-INFO-session_dataset.py(91)] >> labels 12
[2024/04/22 03:15-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75train.pkl, size 180878x3
[2024/04/22 03:15-INFO-session_dataset.py(74)] >> 文件大小 180878 3
[2024/04/22 03:15-INFO-session_dataset.py(91)] >> labels 12
[2024/04/22 03:15-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75test.pkl, size 20093x3
[2024/04/22 03:15-INFO-session_dataset.py(74)] >> 文件大小 20093 3
[2024/04/22 03:15-INFO-session_dataset.py(91)] >> labels 12
[2024/04/22 03:15-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75test.pkl, size 20093x3
[2024/04/22 03:15-INFO-session_dataset.py(74)] >> 文件大小 20093 3
[2024/04/22 03:15-INFO-session_dataset.py(91)] >> labels 12
[2024/04/27 19:25-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/27 19:25-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/27 19:25-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/27 19:25-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/27 19:25-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/27 19:25-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/27 19:25-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune-encryptedtestData/runs/Apr27_19-25-10_autodl-container-bf3b118d52-f39e3c0e,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune-encryptedtestData,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune-encryptedtestData,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/04/27 19:25-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/27 19:25-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/27 19:25-INFO-session_dataset.py(91)] >> labels 7
[2024/04/27 19:25-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/27 19:25-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/27 19:25-INFO-session_dataset.py(91)] >> labels 7
[2024/04/27 19:25-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/27 19:25-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/27 19:25-INFO-session_dataset.py(91)] >> labels 7
[2024/04/27 19:25-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/27 19:25-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/27 19:25-INFO-session_dataset.py(91)] >> labels 7
[2024/04/27 20:10-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/27 20:10-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/27 20:10-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/27 20:10-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/27 20:10-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune-encryptedtestData2/runs/Apr27_20-10-53_autodl-container-bf3b118d52-f39e3c0e,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune-encryptedtestData2,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune-encryptedtestData2,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/04/27 20:10-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/27 20:10-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/27 20:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData2/pretrain4096_0.75train.pkl, size 111790x3
[2024/04/27 20:10-INFO-session_dataset.py(74)] >> 文件大小 111790 3
[2024/04/27 20:10-INFO-session_dataset.py(91)] >> labels 6
[2024/04/27 20:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData2/pretrain4096_0.75train.pkl, size 111790x3
[2024/04/27 20:10-INFO-session_dataset.py(74)] >> 文件大小 111790 3
[2024/04/27 20:10-INFO-session_dataset.py(91)] >> labels 6
[2024/04/27 20:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData2/pretrain4096_0.75test.pkl, size 12418x3
[2024/04/27 20:10-INFO-session_dataset.py(74)] >> 文件大小 12418 3
[2024/04/27 20:10-INFO-session_dataset.py(91)] >> labels 6
[2024/04/27 20:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData2/pretrain4096_0.75test.pkl, size 12418x3
[2024/04/27 20:10-INFO-session_dataset.py(74)] >> 文件大小 12418 3
[2024/04/27 20:10-INFO-session_dataset.py(91)] >> labels 6
[2024/04/28 19:34-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/28 19:34-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/28 19:34-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/28 19:34-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/28 19:34-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/28 19:34-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/28 19:34-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4098/runs/Apr28_19-34-35_autodl-container-fbdc119552-6eb417c1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4098,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=256,
per_device_train_batch_size=256,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4098,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.1,
xpu_backend=None,
)
[2024/04/28 19:34-INFO-pretrain.py(112)] >> load PreTrained model from /root/autodl-tmp/Flow-MAE/vit-mae-4097/checkpoint-360500
[2024/04/28 19:34-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/28 19:34-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/28 19:34-INFO-session_dataset.py(91)] >> labels 7
[2024/04/28 19:34-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/28 19:34-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/28 19:34-INFO-session_dataset.py(91)] >> labels 7
[2024/04/28 19:34-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/28 19:34-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/28 19:34-INFO-session_dataset.py(91)] >> labels 7
[2024/04/28 19:34-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/28 19:34-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/28 19:34-INFO-session_dataset.py(91)] >> labels 7
[2024/04/28 19:36-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/28 19:36-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/28 19:36-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/28 19:36-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/28 19:36-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/28 19:36-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/28 19:36-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4098/runs/Apr28_19-36-27_autodl-container-fbdc119552-6eb417c1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4098,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=256,
per_device_train_batch_size=256,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4098,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.1,
xpu_backend=None,
)
[2024/04/28 19:36-INFO-pretrain.py(112)] >> load PreTrained model from /root/autodl-tmp/Flow-MAE/vit-mae-4097/checkpoint-360500
[2024/04/28 19:36-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/28 19:36-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/28 19:36-INFO-session_dataset.py(91)] >> labels 7
[2024/04/28 19:36-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/28 19:36-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/28 19:36-INFO-session_dataset.py(91)] >> labels 7
[2024/04/28 19:36-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/28 19:36-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/28 19:36-INFO-session_dataset.py(91)] >> labels 7
[2024/04/28 19:36-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/28 19:36-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/28 19:36-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 00:42-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/29 00:42-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/29 00:42-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 00:42-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 00:42-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune-encryptedtestData2/runs/Apr29_00-42-02_autodl-container-fbdc119552-6eb417c1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune-encryptedtestData2,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune-encryptedtestData2,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/04/29 00:42-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 00:42-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 00:42-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData2/pretrain4096_0.75train.pkl, size 111790x3
[2024/04/29 00:42-INFO-session_dataset.py(74)] >> 文件大小 111790 3
[2024/04/29 00:42-INFO-session_dataset.py(91)] >> labels 6
[2024/04/29 00:42-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData2/pretrain4096_0.75test.pkl, size 12418x3
[2024/04/29 00:42-INFO-session_dataset.py(74)] >> 文件大小 12418 3
[2024/04/29 00:42-INFO-session_dataset.py(91)] >> labels 6
[2024/04/29 00:42-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData2/pretrain4096_0.75train.pkl, size 111790x3
[2024/04/29 00:42-INFO-session_dataset.py(74)] >> 文件大小 111790 3
[2024/04/29 00:42-INFO-session_dataset.py(91)] >> labels 6
[2024/04/29 00:42-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData2/pretrain4096_0.75test.pkl, size 12418x3
[2024/04/29 00:42-INFO-session_dataset.py(74)] >> 文件大小 12418 3
[2024/04/29 00:42-INFO-session_dataset.py(91)] >> labels 6
[2024/04/29 01:04-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/29 01:04-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/29 01:04-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 01:04-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 01:04-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune-encryptedtestData/runs/Apr29_01-04-51_autodl-container-fbdc119552-6eb417c1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune-encryptedtestData,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune-encryptedtestData,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/04/29 01:04-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 01:04-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 01:04-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 01:04-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 01:04-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 01:04-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 01:04-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:04-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:04-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 01:04-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 01:04-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:04-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 01:04-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 01:04-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:28-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/29 01:28-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/29 01:28-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 01:28-WARNING-pretrain.py(140)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/29 01:28-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 01:28-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/04/29 01:28-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-4098/runs/Apr29_01-28-24_autodl-container-fbdc119552-6eb417c1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-4098,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=256,
per_device_train_batch_size=256,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-4098,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.1,
xpu_backend=None,
)
[2024/04/29 01:28-INFO-pretrain.py(112)] >> load PreTrained model from /root/autodl-tmp/Flow-MAE/vit-mae-4097/checkpoint-360500
[2024/04/29 01:28-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 01:28-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 01:28-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:28-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 01:28-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 01:28-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:28-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 01:28-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 01:28-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:28-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 01:28-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 01:28-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:29-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/29 01:29-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/29 01:29-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 01:29-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 01:29-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 01:29-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 01:29-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune-encryptedtestData/runs/Apr29_01-29-41_autodl-container-fbdc119552-6eb417c1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune-encryptedtestData,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune-encryptedtestData,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/04/29 01:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 01:29-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 01:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 01:29-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 01:29-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:29-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 01:29-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 01:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 01:29-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 01:29-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:29-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:30-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/29 01:30-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/29 01:30-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 01:30-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 01:30-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 01:30-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 01:30-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune-encryptedtestData/runs/Apr29_01-30-31_autodl-container-fbdc119552-6eb417c1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune-encryptedtestData,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune-encryptedtestData,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/04/29 01:30-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 01:30-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 01:30-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 01:30-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 01:30-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:30-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:30-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 01:30-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 01:30-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:30-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 01:30-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 01:30-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:31-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/29 01:31-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/29 01:31-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 01:31-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 01:31-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 01:31-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 01:31-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune-encryptedtestData/runs/Apr29_01-31-23_autodl-container-fbdc119552-6eb417c1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=500.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune-encryptedtestData,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=16,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune-encryptedtestData,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/04/29 01:31-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 01:31-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 01:31-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:31-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 01:31-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 01:31-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:31-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 01:31-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 01:31-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:31-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 01:31-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 01:31-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:34-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/29 01:34-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/29 01:34-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 01:34-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 01:34-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 01:34-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 01:34-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune-encryptedtestData/runs/Apr29_01-34-55_autodl-container-fbdc119552-6eb417c1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune-encryptedtestData,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune-encryptedtestData,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/04/29 01:34-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 01:34-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 01:34-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:34-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 01:34-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 01:34-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:34-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 01:34-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 01:34-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 01:34-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 01:34-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 01:34-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 10:20-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/04/29 10:20-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/04/29 10:20-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 10:20-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 10:20-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/04/29 10:20-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/04/29 10:20-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune-encryptedtestData/runs/Apr29_10-20-59_autodl-container-724e11b152-551b31a9,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune-encryptedtestData,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune-encryptedtestData,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/04/29 10:21-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 10:21-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 10:21-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/04/29 10:21-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/04/29 10:21-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 10:21-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 10:21-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 10:21-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 10:21-INFO-session_dataset.py(91)] >> labels 7
[2024/04/29 10:21-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/04/29 10:21-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/04/29 10:21-INFO-session_dataset.py(91)] >> labels 7
[2024/05/01 16:27-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/01 16:27-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/05/01 16:27-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/01 16:27-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune-testForDelete/runs/May01_16-27-43_autodl-container-d823118352-76ba9aed,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune-testForDelete,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune-testForDelete,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/01 16:27-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75train.pkl, size 95985x3
[2024/05/01 16:27-INFO-session_dataset.py(74)] >> 文件大小 95985 3
[2024/05/01 16:27-INFO-session_dataset.py(91)] >> labels 7
[2024/05/01 16:27-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/encryptedtestData/pretrain4096_0.75test.pkl, size 10662x3
[2024/05/01 16:27-INFO-session_dataset.py(74)] >> 文件大小 10662 3
[2024/05/01 16:27-INFO-session_dataset.py(91)] >> labels 7
[2024/05/04 18:12-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/04 18:12-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/05/04 18:12-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/05/04 18:12-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-pretrainwithprobe/runs/May04_18-12-40_autodl-container-b37a11a83c-1af0d997,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-pretrainwithprobe,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-pretrainwithprobe,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.1,
xpu_backend=None,
)
[2024/05/04 18:12-INFO-pretrain.py(112)] >> load PreTrained model from /root/autodl-tmp/Flow-MAE/vit-mae-4097/checkpoint-360500
[2024/05/04 18:12-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75train.pkl, size 180878x3
[2024/05/04 18:12-INFO-session_dataset.py(74)] >> 文件大小 180878 3
[2024/05/04 18:12-INFO-session_dataset.py(91)] >> labels 12
[2024/05/04 18:12-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75test.pkl, size 20093x3
[2024/05/04 18:12-INFO-session_dataset.py(74)] >> 文件大小 20093 3
[2024/05/04 18:12-INFO-session_dataset.py(91)] >> labels 12
[2024/05/04 18:15-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/04 18:15-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/05/04 18:15-WARNING-pretrain.py(140)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True
[2024/05/04 18:15-INFO-pretrain.py(144)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-pretrainwithprobe/runs/May04_18-15-42_autodl-container-b37a11a83c-1af0d997,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-pretrainwithprobe,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-pretrainwithprobe,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1234,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.1,
xpu_backend=None,
)
[2024/05/04 18:15-INFO-pretrain.py(112)] >> load PreTrained model from /root/autodl-tmp/Flow-MAE/vit-mae-4097/checkpoint-360500
[2024/05/04 18:15-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75train.pkl, size 180878x3
[2024/05/04 18:15-INFO-session_dataset.py(74)] >> 文件大小 180878 3
[2024/05/04 18:15-INFO-session_dataset.py(91)] >> labels 12
[2024/05/04 18:15-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FinetunetestData/pretrain4096_0.75test.pkl, size 20093x3
[2024/05/04 18:15-INFO-session_dataset.py(74)] >> 文件大小 20093 3
[2024/05/04 18:15-INFO-session_dataset.py(91)] >> labels 12
[2024/05/05 20:11-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/05 20:11-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/05/05 20:11-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/05 20:11-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneWithOutProbe/runs/May05_20-11-32_autodl-container-b37a11a83c-1af0d997,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=100.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneWithOutProbe,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneWithOutProbe,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/05 20:11-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 325479x3
[2024/05/05 20:11-INFO-session_dataset.py(74)] >> 文件大小 325479 3
[2024/05/05 20:11-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 20:11-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 36162x3
[2024/05/05 20:11-INFO-session_dataset.py(74)] >> 文件大小 36162 3
[2024/05/05 20:11-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 21:52-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/05 21:52-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/05/05 21:52-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/05 21:52-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneWithOutProbe/runs/May05_21-52-40_autodl-container-d823118352-76ba9aed,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=100.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneWithOutProbe,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneWithOutProbe,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/05 21:52-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/05 21:52-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/05 21:52-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 21:52-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/05 21:52-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/05 21:52-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 21:54-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/05 21:54-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/05/05 21:54-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/05 21:54-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/05 21:54-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/05 21:54-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/05 21:54-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneWithProbe/runs/May05_21-54-52_autodl-container-d823118352-76ba9aed,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=100.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneWithProbe,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneWithProbe,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/05 21:54-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/05 21:54-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/05 21:54-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 21:54-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/05 21:54-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/05 21:54-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 21:54-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/05 21:54-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/05 21:54-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 21:54-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/05 21:54-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/05 21:54-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 21:55-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/05 21:55-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/05/05 21:55-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/05 21:55-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneWithProbe/runs/May05_21-55-21_autodl-container-d823118352-76ba9aed,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=100.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneWithProbe,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneWithProbe,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/05 21:55-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/05 21:55-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/05 21:55-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 21:55-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/05 21:55-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/05 21:55-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 21:56-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/05 21:56-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/05/05 21:56-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/05 21:56-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/05 21:56-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/05 21:56-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/05 21:56-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneWithOutProbe/runs/May05_21-56-39_autodl-container-d823118352-76ba9aed,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=100.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneWithOutProbe,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneWithOutProbe,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/05 21:56-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/05 21:56-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/05 21:56-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/05 21:56-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/05 21:56-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 21:56-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 21:56-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/05 21:56-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/05 21:56-INFO-session_dataset.py(91)] >> labels 7
[2024/05/05 21:56-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/05 21:56-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/05 21:56-INFO-session_dataset.py(91)] >> labels 7
[2024/05/06 00:39-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/06 00:39-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/05/06 00:39-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/06 00:39-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/06 00:39-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/06 00:39-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/06 00:39-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneWithProbe/runs/May06_00-39-16_autodl-container-d823118352-76ba9aed,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=100.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneWithProbe,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneWithProbe,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/06 00:39-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/06 00:39-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/06 00:39-INFO-session_dataset.py(91)] >> labels 7
[2024/05/06 00:39-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/06 00:39-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/06 00:39-INFO-session_dataset.py(91)] >> labels 7
[2024/05/06 00:39-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/06 00:39-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/06 00:39-INFO-session_dataset.py(91)] >> labels 7
[2024/05/06 00:39-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/06 00:39-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/06 00:39-INFO-session_dataset.py(91)] >> labels 7
[2024/05/09 10:06-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/05/09 10:06-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/09 10:06-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/09 10:06-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/09 10:06-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/09 10:06-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneWithProbe2/runs/May09_10-06-30_autodl-container-b37a11a83c-1af0d997,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneWithProbe2,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneWithProbe2,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/09 10:06-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/09 10:06-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/09 10:06-INFO-session_dataset.py(91)] >> labels 7
[2024/05/09 10:06-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/09 10:06-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/09 10:06-INFO-session_dataset.py(91)] >> labels 7
[2024/05/09 10:09-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/09 10:09-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/05/09 10:09-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/09 10:09-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/09 10:09-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/09 10:09-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneWithProbe2/runs/May09_10-09-56_autodl-container-b37a11a83c-1af0d997,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneWithProbe2,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneWithProbe2,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/09 10:09-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/09 10:09-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/09 10:09-INFO-session_dataset.py(91)] >> labels 7
[2024/05/09 10:09-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/09 10:09-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/09 10:09-INFO-session_dataset.py(91)] >> labels 7
[2024/05/09 10:10-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/09 10:10-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/05/09 10:10-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/09 10:10-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneWithProbe2/runs/May09_10-10-24_autodl-container-b37a11a83c-1af0d997,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneWithProbe2,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneWithProbe2,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/09 10:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/09 10:10-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/09 10:10-INFO-session_dataset.py(91)] >> labels 7
[2024/05/09 10:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/09 10:10-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/09 10:10-INFO-session_dataset.py(91)] >> labels 7
[2024/05/09 11:03-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/09 11:03-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/05/09 11:03-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/09 11:03-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneWithProbe3/runs/May09_11-03-52_autodl-container-b37a11a83c-1af0d997,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneWithProbe3,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneWithProbe3,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/09 11:03-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/09 11:03-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/09 11:03-INFO-session_dataset.py(91)] >> labels 7
[2024/05/09 11:03-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/09 11:03-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/09 11:03-INFO-session_dataset.py(91)] >> labels 7
[2024/05/09 11:39-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/09 11:39-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/05/09 11:39-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/09 11:39-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneWithOutProbe2/runs/May09_11-39-31_autodl-container-b37a11a83c-1af0d997,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneWithOutProbe2,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneWithOutProbe2,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/09 11:39-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/09 11:39-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/09 11:39-INFO-session_dataset.py(91)] >> labels 7
[2024/05/09 11:39-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/09 11:39-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/09 11:39-INFO-session_dataset.py(91)] >> labels 7
[2024/05/09 12:54-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/09 12:54-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/05/09 12:54-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/09 12:54-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneWithOutProbe3/runs/May09_12-54-12_autodl-container-b37a11a83c-1af0d997,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneWithOutProbe3,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneWithOutProbe3,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/09 12:54-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/05/09 12:54-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/05/09 12:54-INFO-session_dataset.py(91)] >> labels 7
[2024/05/09 12:54-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/05/09 12:54-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/05/09 12:54-INFO-session_dataset.py(91)] >> labels 7
[2024/05/10 18:29-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/10 18:29-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/05/10 18:29-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/10 18:29-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneVPN_TOR_Benign/runs/May10_18-29-01_autodl-container-d823118352-76ba9aed,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneVPN_TOR_Benign,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneVPN_TOR_Benign,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/10 18:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/VPN_TOR_BenigntestData/pretrain4096_0.75train.pkl, size 270000x3
[2024/05/10 18:29-INFO-session_dataset.py(74)] >> 文件大小 270000 3
[2024/05/10 18:29-INFO-session_dataset.py(91)] >> labels 3
[2024/05/10 18:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/VPN_TOR_BenigntestData/pretrain4096_0.75test.pkl, size 30000x3
[2024/05/10 18:29-INFO-session_dataset.py(74)] >> 文件大小 30000 3
[2024/05/10 18:29-INFO-session_dataset.py(91)] >> labels 3
[2024/05/10 18:29-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/05/10 18:29-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/10 18:29-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/10 18:29-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/10 18:29-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetuneVPN_TOR_Benign/runs/May10_18-29-18_autodl-container-d823118352-76ba9aed,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_hf,
output_dir=./vit-mae-finetuneVPN_TOR_Benign,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetuneVPN_TOR_Benign,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/10 18:29-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/10 18:29-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/10 18:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/VPN_TOR_BenigntestData/pretrain4096_0.75train.pkl, size 270000x3
[2024/05/10 18:29-INFO-session_dataset.py(74)] >> 文件大小 270000 3
[2024/05/10 18:29-INFO-session_dataset.py(91)] >> labels 3
[2024/05/10 18:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/VPN_TOR_BenigntestData/pretrain4096_0.75train.pkl, size 270000x3
[2024/05/10 18:29-INFO-session_dataset.py(74)] >> 文件大小 270000 3
[2024/05/10 18:29-INFO-session_dataset.py(91)] >> labels 3
[2024/05/10 18:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/VPN_TOR_BenigntestData/pretrain4096_0.75test.pkl, size 30000x3
[2024/05/10 18:29-INFO-session_dataset.py(74)] >> 文件大小 30000 3
[2024/05/10 18:29-INFO-session_dataset.py(91)] >> labels 3
[2024/05/10 18:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/VPN_TOR_BenigntestData/pretrain4096_0.75test.pkl, size 30000x3
[2024/05/10 18:29-INFO-session_dataset.py(74)] >> 文件大小 30000 3
[2024/05/10 18:29-INFO-session_dataset.py(91)] >> labels 3
[2024/05/10 20:25-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/05/10 20:25-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/10 20:25-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/10 20:25-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/10 20:25-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune100VPN_TOR_Benign/runs/May10_20-25-06_autodl-container-d823118352-76ba9aed,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=100.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune100VPN_TOR_Benign,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune100VPN_TOR_Benign,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/10 20:25-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/10 20:25-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/10 20:25-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/VPN_TOR_BenigntestData/pretrain4096_0.75train.pkl, size 270000x3
[2024/05/10 20:25-INFO-session_dataset.py(74)] >> 文件大小 270000 3
[2024/05/10 20:25-INFO-session_dataset.py(91)] >> labels 3
[2024/05/10 20:25-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/VPN_TOR_BenigntestData/pretrain4096_0.75test.pkl, size 30000x3
[2024/05/10 20:25-INFO-session_dataset.py(74)] >> 文件大小 30000 3
[2024/05/10 20:25-INFO-session_dataset.py(91)] >> labels 3
[2024/05/10 20:25-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/VPN_TOR_BenigntestData/pretrain4096_0.75train.pkl, size 270000x3
[2024/05/10 20:25-INFO-session_dataset.py(74)] >> 文件大小 270000 3
[2024/05/10 20:25-INFO-session_dataset.py(91)] >> labels 3
[2024/05/10 20:25-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/VPN_TOR_BenigntestData/pretrain4096_0.75test.pkl, size 30000x3
[2024/05/10 20:25-INFO-session_dataset.py(74)] >> 文件大小 30000 3
[2024/05/10 20:25-INFO-session_dataset.py(91)] >> labels 3
[2024/05/11 01:10-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/05/11 01:10-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/11 01:10-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/11 01:10-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/11 01:10-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune100PLUS_VPN_TOPtest/runs/May11_01-10-21_autodl-container-d823118352-76ba9aed,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=100.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune100PLUS_VPN_TOPtest,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune100PLUS_VPN_TOPtest,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/11 01:10-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/11 01:10-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/11 01:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/PLUS_VPN_TOPtest/pretrain4096_0.75train.pkl, size 876391x3
[2024/05/11 01:10-INFO-session_dataset.py(74)] >> 文件大小 876391 3
[2024/05/11 01:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/PLUS_VPN_TOPtest/pretrain4096_0.75train.pkl, size 876391x3
[2024/05/11 01:10-INFO-session_dataset.py(74)] >> 文件大小 876391 3
[2024/05/11 01:10-INFO-session_dataset.py(91)] >> labels 18
[2024/05/11 01:10-INFO-session_dataset.py(91)] >> labels 18
[2024/05/11 01:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/PLUS_VPN_TOPtest/pretrain4096_0.75test.pkl, size 97371x3
[2024/05/11 01:10-INFO-session_dataset.py(74)] >> 文件大小 97371 3
[2024/05/11 01:10-INFO-session_dataset.py(91)] >> labels 18
[2024/05/11 01:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/PLUS_VPN_TOPtest/pretrain4096_0.75test.pkl, size 97371x3
[2024/05/11 01:10-INFO-session_dataset.py(74)] >> 文件大小 97371 3
[2024/05/11 01:10-INFO-session_dataset.py(91)] >> labels 18
[2024/05/11 01:12-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/05/11 01:12-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 1
[2024/05/11 01:12-INFO-distributed_c10d.py(262)] >> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/11 01:12-WARNING-finetune.py(172)] >> Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/11 01:12-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
[2024/05/11 01:12-WARNING-finetune.py(172)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/05/11 01:12-INFO-finetune.py(176)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-finetune100PLUS_VPN_TOPtest/runs/May11_01-12-01_autodl-container-d823118352-76ba9aed,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=100.0,
optim=adamw_hf,
output_dir=./vit-mae-finetune100PLUS_VPN_TOPtest,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-finetune100PLUS_VPN_TOPtest,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/05/11 01:12-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/PLUS_VPN_TOPtest/pretrain4096_0.75train.pkl, size 876391x3
[2024/05/11 01:12-INFO-session_dataset.py(74)] >> 文件大小 876391 3
[2024/05/11 01:12-INFO-session_dataset.py(91)] >> labels 18
[2024/05/11 01:12-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/PLUS_VPN_TOPtest/pretrain4096_0.75train.pkl, size 876391x3
[2024/05/11 01:12-INFO-session_dataset.py(74)] >> 文件大小 876391 3
[2024/05/11 01:12-INFO-session_dataset.py(91)] >> labels 18
[2024/05/11 01:12-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/PLUS_VPN_TOPtest/pretrain4096_0.75test.pkl, size 97371x3
[2024/05/11 01:12-INFO-session_dataset.py(74)] >> 文件大小 97371 3
[2024/05/11 01:12-INFO-session_dataset.py(91)] >> labels 18
[2024/05/11 01:12-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/PLUS_VPN_TOPtest/pretrain4096_0.75test.pkl, size 97371x3
[2024/05/11 01:12-INFO-session_dataset.py(74)] >> 文件大小 97371 3
[2024/05/11 01:12-INFO-session_dataset.py(91)] >> labels 18
[2024/07/04 16:09-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/07/04 16:09-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/07/04 16:09-WARNING-student.py(170)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/07/04 16:09-INFO-student.py(174)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student/runs/Jul04_16-09-54_autodl-container-ecb6118152-b309df6b,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=100.0,
optim=adamw_hf,
output_dir=./vit-mae-student,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/07/04 16:09-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/07/04 16:09-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/07/04 16:09-INFO-session_dataset.py(91)] >> labels 7
[2024/07/04 16:09-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/04 16:09-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/04 16:09-INFO-session_dataset.py(91)] >> labels 7
[2024/07/04 16:09-WARNING-student.py(101)] >> You are instantiating a new config instance from scratch.
[2024/07/05 22:59-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/07/05 22:59-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/07/05 22:59-WARNING-student.py(170)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/07/05 22:59-INFO-student.py(174)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-compare/runs/Jul05_22-59-48_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=100.0,
optim=adamw_hf,
output_dir=./vit-mae-student-compare,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-compare,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/07/05 22:59-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/07/05 22:59-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/07/05 22:59-INFO-session_dataset.py(91)] >> labels 7
[2024/07/05 22:59-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/05 22:59-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/05 22:59-INFO-session_dataset.py(91)] >> labels 7
[2024/07/05 22:59-WARNING-student.py(101)] >> You are instantiating a new config instance from scratch.
[2024/07/05 23:32-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/07/05 23:32-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/07/05 23:32-WARNING-student.py(170)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/07/05 23:32-INFO-student.py(174)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student2/runs/Jul05_23-32-07_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=100.0,
optim=adamw_hf,
output_dir=./vit-mae-student2,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student2,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/07/05 23:32-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/07/05 23:32-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/07/05 23:32-INFO-session_dataset.py(91)] >> labels 7
[2024/07/05 23:32-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/05 23:32-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/05 23:32-INFO-session_dataset.py(91)] >> labels 7
[2024/07/05 23:32-WARNING-student.py(101)] >> You are instantiating a new config instance from scratch.
[2024/07/06 23:02-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/07/06 23:02-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/07/06 23:02-WARNING-student.py(170)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/07/06 23:02-INFO-student.py(174)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student/runs/Jul06_23-02-46_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/07/06 23:02-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/07/06 23:02-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/07/06 23:02-INFO-session_dataset.py(91)] >> labels 7
[2024/07/06 23:02-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/06 23:02-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/06 23:02-INFO-session_dataset.py(91)] >> labels 7
[2024/07/06 23:02-WARNING-student.py(101)] >> You are instantiating a new config instance from scratch.
[2024/07/06 23:08-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/07/06 23:08-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/07/06 23:08-WARNING-student.py(189)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/07/06 23:08-INFO-student.py(193)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student/runs/Jul06_23-08-26_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/07/06 23:08-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/07/06 23:08-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/07/06 23:08-INFO-session_dataset.py(91)] >> labels 7
[2024/07/06 23:08-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/06 23:08-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/06 23:08-INFO-session_dataset.py(91)] >> labels 7
[2024/07/06 23:08-WARNING-student.py(102)] >> You are instantiating a new config instance from scratch.
[2024/07/06 23:10-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/07/06 23:10-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/07/06 23:10-WARNING-student.py(189)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/07/06 23:10-INFO-student.py(193)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student/runs/Jul06_23-10-39_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/07/06 23:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/07/06 23:10-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/07/06 23:10-INFO-session_dataset.py(91)] >> labels 7
[2024/07/06 23:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/06 23:10-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/06 23:10-INFO-session_dataset.py(91)] >> labels 7
[2024/07/06 23:10-WARNING-student.py(102)] >> You are instantiating a new config instance from scratch.
[2024/07/07 14:27-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:27-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:27-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:29-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:29-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:29-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:29-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:31-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:31-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:31-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:32-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:32-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:32-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:34-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:34-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:34-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:34-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:34-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:34-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:35-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:35-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:35-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:37-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:37-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:37-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:37-WARNING-font_manager.py(1350)] >> findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.
[2024/07/07 14:37-WARNING-font_manager.py(1355)] >> findfont: Generic family 'serif' not found because none of the following families were found: Times New Roman
[2024/07/07 14:40-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/07/07 14:40-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/07/07 14:40-WARNING-student.py(189)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/07/07 14:40-INFO-student.py(193)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-compare/runs/Jul07_14-40-47_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-compare,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-compare,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/07/07 14:40-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/07/07 14:40-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/07/07 14:40-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:40-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:40-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:40-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:40-WARNING-student.py(102)] >> You are instantiating a new config instance from scratch.
[2024/07/07 14:41-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:41-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:41-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:41-WARNING-font_manager.py(1350)] >> findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.
[2024/07/07 14:41-WARNING-font_manager.py(1355)] >> findfont: Generic family 'serif' not found because none of the following families were found: Times New Roman
[2024/07/07 14:47-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:47-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:47-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:50-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:50-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:50-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 14:52-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 14:52-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 14:52-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 15:03-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 15:03-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 15:03-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 15:07-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 15:07-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 15:07-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 15:08-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 15:08-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 15:08-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 15:09-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 15:09-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 15:09-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 15:09-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 15:09-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 15:09-INFO-session_dataset.py(91)] >> labels 7
[2024/07/07 15:10-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/07/07 15:10-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/07/07 15:10-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 15:12-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 15:12-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 15:14-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 15:14-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 15:14-WARNING-student.py(197)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 15:14-INFO-student.py(201)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-response/runs/Aug18_15-14-27_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
model_type=response,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-response,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-response,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 15:14-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 15:14-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 15:14-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 15:14-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 15:14-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 15:14-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 15:14-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 15:14-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 15:14-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 15:14-WARNING-student.py(197)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 15:14-INFO-student.py(201)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-response/runs/Aug18_15-14-50_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-response,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-response,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 15:14-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 15:14-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 15:14-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 15:14-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 15:14-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 15:14-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 15:14-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 15:29-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 15:29-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 15:29-WARNING-student.py(197)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 15:29-INFO-student.py(201)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-response/runs/Aug18_15-29-01_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-response,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-response,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 15:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 15:29-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 15:29-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 15:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 15:29-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 15:29-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 15:29-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:04-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:04-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:04-WARNING-student.py(197)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:04-INFO-student.py(201)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-04-19_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:04-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:04-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:04-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:04-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:04-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:04-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:04-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:05-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:05-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:05-WARNING-student.py(197)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:05-INFO-student.py(201)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-05-21_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:05-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:05-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:05-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:05-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:05-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:05-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:05-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:09-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:09-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:09-WARNING-student.py(197)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:09-INFO-student.py(201)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-09-53_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:09-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:09-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:09-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:09-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:09-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:09-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:09-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:15-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:15-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:15-WARNING-student.py(197)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:15-INFO-student.py(201)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-15-10_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:15-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:15-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:15-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:15-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:15-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:15-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:15-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:17-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:17-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:17-WARNING-student.py(197)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:17-INFO-student.py(201)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-17-05_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:17-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:17-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:17-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:17-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:17-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:17-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:17-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:18-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:18-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:18-WARNING-student.py(197)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:18-INFO-student.py(201)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-18-52_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:18-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:18-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:18-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:18-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:18-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:18-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:18-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:21-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:21-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:21-WARNING-student.py(202)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:21-INFO-student.py(206)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-21-47_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:21-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:21-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:21-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:21-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:21-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:21-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:21-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:25-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:25-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:25-WARNING-student.py(202)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:25-INFO-student.py(206)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-25-13_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:25-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:25-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:25-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:25-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:25-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:25-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:25-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:29-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:29-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:29-WARNING-student.py(204)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:29-INFO-student.py(208)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-29-20_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:29-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:29-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:29-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:29-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:29-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:29-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:31-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:31-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:31-WARNING-student.py(206)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:31-INFO-student.py(210)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-31-05_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:31-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:31-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:31-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:31-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:31-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:31-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:31-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:37-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:37-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:37-WARNING-student.py(206)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:37-INFO-student.py(210)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-37-50_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:37-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:37-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:37-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:37-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:37-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:37-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:37-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:38-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:38-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:38-WARNING-student.py(206)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:38-INFO-student.py(210)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-38-26_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:38-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:38-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:38-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:38-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:38-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:38-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:38-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/18 19:39-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/18 19:39-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/18 19:39-WARNING-student.py(206)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/18 19:39-INFO-student.py(210)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-feature/runs/Aug18_19-39-37_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-feature,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-feature,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/18 19:39-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/18 19:39-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/18 19:39-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:39-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/18 19:39-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/18 19:39-INFO-session_dataset.py(91)] >> labels 7
[2024/08/18 19:39-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/19 13:11-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/19 13:11-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/19 13:11-WARNING-student.py(206)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/19 13:11-INFO-student.py(210)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-relation/runs/Aug19_13-11-03_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-relation,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-relation,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/19 13:11-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/19 13:11-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/19 13:11-INFO-session_dataset.py(91)] >> labels 7
[2024/08/19 13:11-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/19 13:11-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/19 13:11-INFO-session_dataset.py(91)] >> labels 7
[2024/08/19 13:11-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/19 13:16-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/19 13:16-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/19 13:16-WARNING-student.py(206)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/19 13:16-INFO-student.py(210)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student-relation/runs/Aug19_13-16-48_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student-relation,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student-relation,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/19 13:16-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/19 13:16-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/19 13:16-INFO-session_dataset.py(91)] >> labels 7
[2024/08/19 13:16-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/19 13:16-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/19 13:16-INFO-session_dataset.py(91)] >> labels 7
[2024/08/19 13:16-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/20 15:26-INFO-distributed_c10d.py(228)] >> Added key: store_based_barrier_key:1 to store for rank: 0
[2024/08/20 15:26-INFO-distributed_c10d.py(262)] >> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2024/08/20 15:26-WARNING-student.py(206)] >> Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
[2024/08/20 15:26-INFO-student.py(210)] >> Training/evaluation parameters CustomTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
base_learning_rate=0.0001,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=passive,
log_on_each_node=True,
logging_dir=./vit-mae-student/runs/Aug20_15-26-28_autodl-container-049b4b88f8-decc1395,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=steps,
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=eval_f1,
mp_parameters=,
no_cuda=False,
num_train_epochs=200.0,
optim=adamw_hf,
output_dir=./vit-mae-student,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=64,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=./vit-mae-student,
save_on_each_node=False,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=1337,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.08,
xpu_backend=None,
)
[2024/08/20 15:26-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75train.pkl, size 45133x3
[2024/08/20 15:26-INFO-session_dataset.py(74)] >> 文件大小 45133 3
[2024/08/20 15:26-INFO-session_dataset.py(91)] >> labels 7
[2024/08/20 15:26-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/20 15:26-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/20 15:26-INFO-session_dataset.py(91)] >> labels 7
[2024/08/20 15:26-WARNING-student.py(103)] >> You are instantiating a new config instance from scratch.
[2024/08/23 15:36-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/23 15:36-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/23 15:36-INFO-session_dataset.py(91)] >> labels 7
[2024/08/23 15:38-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/23 15:38-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/23 15:38-INFO-session_dataset.py(91)] >> labels 7
[2024/08/23 15:39-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/23 15:39-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/23 15:39-INFO-session_dataset.py(91)] >> labels 7
[2024/08/23 15:40-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/23 15:40-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/23 15:40-INFO-session_dataset.py(91)] >> labels 7
[2024/08/23 15:40-INFO-session_dataset.py(180)] >> read /root/autodl-tmp/Flow-MAE/data/FineDatatestP_M/pretrain4096_0.75test.pkl, size 5013x3
[2024/08/23 15:40-INFO-session_dataset.py(74)] >> 文件大小 5013 3
[2024/08/23 15:40-INFO-session_dataset.py(91)] >> labels 7
